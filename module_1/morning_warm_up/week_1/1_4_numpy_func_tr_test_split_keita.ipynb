{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [HARD] warm-up\n",
    "\n",
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a function to split data into training data and testing data\n",
    "##### When applying machine learning algorithms in a supervised learning scenario we want to have data to learn from and some data we have never seen before to test what we have learnt. \n",
    "\n",
    "### We have two tasks: \n",
    "- \tChoosing a condition to split the data on (e.g. we \tgonna choose the year 2010)\n",
    "-  Split the features from the target we want to \tpredict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Open your CO2 notebook (from yesterday) through terminal!\n",
    "`use commands cd and jupyter notebook`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_fwf('ftp://aftp.cmdl.noaa.gov/products/trends/co2/co2_mm_mlo.txt', skiprows=71)\n",
    "df.rename(index=str, columns={\"#\": \"year\", \"Unnamed: 1\": \"month\", \"date\": \"decimal_date\",\"Unnamed: 3\": \"CO2\", \"Unnamed: 4\": \"interpolated\", \"(season corr)\": \"trend\", \"Unnamed: 6\": \"days\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. If not done yesterday, pick the year column, month column, day column and C02 column from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.loc[:,['year', 'month',\"CO2\"]].copy()\n",
    "df2[\"date\"] = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[df2.loc[:,'CO2'] == -99.99, 'CO2'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create the function\n",
    " - cond_df is an array of the column you want to condition your split on\n",
    " - the idea is to use np.where on the condition column to get the indices on which the full dataset will be split\n",
    " - once we have the indices we can use them on the full dataset to make the split. Notice: the indices of the conditioned column and the pandas df are one and the same.\n",
    " - X are all the features and Y should be the CO2 column - please split them before executing the function and assign them to X annd Y \n",
    " \n",
    "`def tr_te_split(X, Y, cond_df, cond):`\n",
    "\n",
    "`cond_df could be an array of the year column`\n",
    "\t\t\t\t\t\t\t\n",
    "`use np.where\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tr_te_split (X, Y, cond_df, cond):\n",
    "    cond_df['cond'] = cond_df[cond] >= 2010"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Check the data sets to see if your split worked (can do manually - with your eyes)\n",
    "\n",
    "\n",
    "### 5. git push it to your branch!\n",
    "\n",
    "\n",
    "### [optional] 6. Explore the use of the describe(), info() and dtypes on the pandas df before turnnnig it to numpy array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
